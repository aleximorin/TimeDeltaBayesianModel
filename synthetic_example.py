import numpy as np
import TimeDeltaBayesianModel as tdbm
from scipy.interpolate import interp1d
import xarray as xr
from netcdf_to_glacier import netcdf_to_glaciermodel

# we use synthetic data generated by Andrew Nolan
path = 'data/k_01-15.nc'
data = xr.open_dataset(path)

# the hacky netcdf_to_glaciermodel function transforms the data in a usable way for the model
# we can use the transient dynamic of the synthetic data to generate different models representing different dynamics

# for example with start_time_i=0 and end_time_i=0, we take the dynamics at time=0 and consider them steady
pre_glacier, PRE_WIDTH, PRE_BDOT, PRE_BED = netcdf_to_glaciermodel(path, 'Steady state', return_model=False,
                                                                   start_time_i=0, end_time_i=1,
                                                                   arbitrary_length_treshold=-1)

# if we take start_time_i=1 and end_time_i=-1, we look at the whole sliding-focused dynamics
syn_glacier, SYN_WIDTH, SYN_BDOT, SYN_BED = netcdf_to_glaciermodel(path, 'Surging', return_model=False,
                                                                   start_time_i=1, end_time_i=-1,
                                                                   arbitrary_length_treshold=-1)

# this glacier model has a longer mesh to take into account the advance of the glacier through the surge.
# the 'final' argument makes sure that the mesh will be long enough
pre_but_for_full_glacier, _, _, _ = netcdf_to_glaciermodel(path, 'Steady state', return_model=False, start_time_i=0,
                                                           end_time_i=1, arbitrary_length_treshold=-1,
                                                           final=len(syn_glacier.velocity.r))

# finally, we can also virtually modify the steady dynamics to last longer.
# here we enforce the steady dynamics to be as long as the surging, i.e 10 years each.
long_glacier, _, _, _ = netcdf_to_glaciermodel(path, 'Long state', return_model=False, start_time_i=0,
                                               end_time_i=-1, arbitrary_length_treshold=-1,
                                               final=len(syn_glacier.velocity.r), dt_steady=10)

# declaring the different models using the different dynamics
pre_model = tdbm.OneDTimeDeltaBayesianModel('Pre-surge', [pre_glacier],
                                            width_path=PRE_WIDTH, bdot_path=PRE_BDOT, bed_path=PRE_BED)
syn_model = tdbm.OneDTimeDeltaBayesianModel('Syn-surge', [syn_glacier],
                                            width_path=SYN_WIDTH, bdot_path=SYN_BDOT, bed_path=SYN_BED)

full_model = tdbm.OneDTimeDeltaBayesianModel('Two timescales', [pre_but_for_full_glacier, syn_glacier],
                                             width_path=SYN_WIDTH, bdot_path=SYN_BDOT, bed_path=SYN_BED)

long_model = tdbm.OneDTimeDeltaBayesianModel('Long model', [long_glacier],
                                             width_path=SYN_WIDTH, bdot_path=SYN_BDOT, bed_path=SYN_BED)

# we can run the inversion for the full modell, taking into account two different time scales in a conjoint inversion
model = full_model
print(f'Initiating {model.name} run')

# defining the grid
mesh = model.bdot.r
dx = 200
mesh = np.arange(mesh[0], mesh[-1], dx)

# here we enforce the bed elevation to be known where the surface is free of ice at the beginning of the simulation
r = data.x.values
bed = data.z_b.values[::-1, 0]
bedF = interp1d(r, bed)
model.bed.r = np.array(list(model.bed.r) + [mesh[-1]])
model.bed.y = np.vstack((model.bed.y, bedF(mesh[-1]))).flatten()

# we want to enforce a zero ice thickness prior
# we then need the lowest surface of every time period involved in the inversion at any given x
surf = model._get_lowest_surface(mesh)
dem_f = interp1d(mesh, surf)
import copy
model.bed.dem_prior = copy.deepcopy(dem_f)

# we finally define the different priors for the model
model.bed.set_1Dprior(sigma=200,
                      lengthscale=1000,
                      mean_function='self.dem_prior',
                      obs_variance=10)

model.bdot.set_1Dprior(sigma=10, lengthscale=1000,
                       mean_function='np.polynomial.Polynomial.fit(self.r.flatten(), self.y, deg=1)',
                       obs_variance=100)
model.width.set_1Dprior(sigma=0.001, obs_variance=0.001,
                        mean_function=lambda x: 1 * np.ones_like(x), lengthscale=1000)

for g in model.glaciers:
    model.glaciers[g].dem.set_1Dprior(sigma=100, lengthscale=1000, mean_function='self.f',
                                      obs_variance=100)
    model.glaciers[g].dhdt.set_1Dprior(sigma=10, lengthscale=1000, mean_function='lambda x: np.zeros_like(x)',
                                       obs_variance=100)
    model.glaciers[g].velocity.set_1Dprior(lengthscale=1000, obs_variance=25,
                                           obs_on_mesh=True)

# we run the mcmc
pow = 5
niter = 10 ** pow
nburn = 10 ** (pow - 1)
nthin = 10
nchains = 3
model.setup_model(mesh)
model.sample(niter, nburn, nthin, nchains)
model.save_sampler('synthetic_model.p')



